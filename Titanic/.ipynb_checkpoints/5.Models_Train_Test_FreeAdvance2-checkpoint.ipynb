{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6716a22e-3256-4b4f-8ad4-0185b2f9d510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.데이터 로드\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "train = pd.read_csv('data/train.csv')\n",
    "\n",
    "X_train = train.drop(columns='Survived')\n",
    "y_train = train['Survived']\n",
    "\n",
    "X_test = pd.read_csv('data/test.csv')\n",
    "PassengerId = X_test['PassengerId'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf30907-db6c-4de8-b310-feb39838b879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#2.EDA\n",
    "import seaborn as sns\n",
    "\n",
    "def graph(variable):\n",
    "    survived = train[train['Survived']==1][variable].value_counts()\n",
    "    dead = train[train['Survived']==0][variable].value_counts()\n",
    "    result = pd.DataFrame([survived,dead])\n",
    "    result.index = ['Survived','Dead']\n",
    "    result.T.plot(kind='bar', color=['skyblue','gray'], rot=0, figsize=(8,6))\n",
    "\n",
    "print(train.info())\n",
    "#graph('Parch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f5c3aa-df94-4a51-aa7c-f24e3f6c66b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.데이터 정제\n",
    "#print(X_train.info())\n",
    "#print(X_train['Fare'].unique())\n",
    "#print(X_train.select_dtypes('object').nunique())\n",
    "\n",
    "#불필요한 컬럼 제거\n",
    "X_train = X_train.drop(columns=['PassengerId','Name','Ticket','Cabin'])\n",
    "X_test = X_test.drop(columns=['PassengerId','Name','Ticket','Cabin'])\n",
    "\n",
    "#SibSp, Parch 컬럼 통합\n",
    "X_train['family'] = X_train['SibSp']+X_train['Parch']\n",
    "X_train = X_train.drop(columns=['SibSp','Parch'])\n",
    "\n",
    "X_test['family'] = X_test['SibSp']+X_test['Parch']\n",
    "X_test = X_test.drop(columns=['SibSp','Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d32119-819b-4924-9c25-2ced4f1daba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.결측치 및 이상치 처리\n",
    "X_train['Age'] = X_train['Age'].fillna(X_train['Age'].mean())\n",
    "X_test['Age'] = X_test['Age'].fillna(X_train['Age'].mean())\n",
    "\n",
    "X_train['Embarked'] = X_train['Embarked'].fillna(X_train['Embarked'].value_counts().idxmax())\n",
    "X_test['Embarked'] = X_test['Embarked'].fillna(X_train['Embarked'].value_counts().idxmax())\n",
    "\n",
    "X_train['Fare'] = X_train['Fare'].fillna(X_train['Fare'].mean())\n",
    "X_test['Fare'] = X_test['Fare'].fillna(X_train['Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba1c7a1-f97a-4111-86d8-61d290ae44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #BK_4.Age컬럼 결측치 대체법\n",
    "# #범주형은 인코딩하고, corr()을 이용해서 상관계수 높은 컬럼 추출\n",
    "\n",
    "# #print(X_train.info())\n",
    "# #print(X_train.select_dtypes('object').nunique())\n",
    "\n",
    "# #X_train = pd.get_dummies(X_train,columns=['Sex','Embarked'])\n",
    "\n",
    "# #X_train[['Age','Fare','Parch','SibSp','Pclass','Sex_female','Sex_male','Embarked_C','Embarked_Q','Embarked_S','Family']].corr()['Age']\n",
    "\n",
    "# #그 컬럼별 group by해서 age 평균을 각 행의 결측치에 대체\n",
    "\n",
    "# Age_By_train = pd.DataFrame(X_train.groupby(['Pclass','family'])['Age'].mean())\n",
    "# Age_By_train = Age_By_train.reset_index()\n",
    "\n",
    "# Age_By_test = pd.DataFrame(X_test.groupby(['Pclass','family'])['Age'].mean())\n",
    "# Age_By_test = Age_By_test.reset_index()\n",
    "\n",
    "\n",
    "# for index, row in Age_By_Pclass.iterrows():\n",
    "#     X_train.loc[(X_train['Pclass'] == row['Pclass']) & (X_train['family'] == row['family']) & (X_train['Age'].isna()), 'Age'] = row['Age']\n",
    "#     X_test.loc[(X_test['Pclass'] == row['Pclass']) & (X_test['family'] == row['family']) & (X_test['Age'].isna()), 'Age'] = row['Age']\n",
    "\n",
    "# # import seaborn as sns\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# # fig,ax = plt.subplots(2,figsize=(40,30))\n",
    "# # sns.countplot(data=X_train,x='Age',ax=ax[0])\n",
    "# # sns.countplot(data=X_test,x='Age',ax=ax[1])\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab931bcb-e7bc-43b2-8bb2-bfb9ac913fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.인코딩\n",
    "X_train = pd.get_dummies(X_train,columns=['Sex','Embarked','Pclass'])\n",
    "X_test = pd.get_dummies(X_test,columns=['Sex','Embarked','Pclass'])\n",
    "\n",
    "X_train_enc = X_train.select_dtypes('bool').astype('int')\n",
    "X_test_enc = X_test.select_dtypes('bool').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba9b552-0097-4537-b2dc-97eb93b69460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_num = X_train.select_dtypes(exclude='bool').copy()\n",
    "X_test_num = X_test.select_dtypes(exclude='bool').copy()\n",
    "\n",
    "scale = StandardScaler().fit(X_train_num)\n",
    "\n",
    "X_train_std = scale.transform(X_train_num)\n",
    "X_test_std = scale.transform(X_test_num)\n",
    "\n",
    "X_train_std = pd.DataFrame(X_train_std,columns=['Age','family','Fare'])\n",
    "X_test_std = pd.DataFrame(X_test_std,columns=['Age','family','Fare'])\n",
    "\n",
    "X_train = pd.concat([X_train_std,X_train_enc],axis=1)\n",
    "X_test = pd.concat([X_test_std,X_test_enc],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b68bb37-40da-40ea-9878-999f5f55d9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'family', 'Fare', 'Sex_female', 'Embarked_S', 'Pclass_3'], dtype='object')\n",
      "[0.16663802 0.21722868 0.08560329 0.39942311 0.02429701 0.10680989]\n"
     ]
    }
   ],
   "source": [
    "#7.특성 선택\n",
    "#RFE\n",
    "from sklearn.feature_selection import RFE, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "X = X_train.drop(columns=['Sex_male','Embarked_C','Pclass_1'])\n",
    "y = y_train\n",
    "test = X_test.drop(columns=['Sex_male','Embarked_C','Pclass_1'])\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "                    max_depth=7,\n",
    "                    n_estimators=200,\n",
    "                    max_features='sqrt',\n",
    "                    min_samples_split=2,\n",
    "                    min_samples_leaf=1,\n",
    "                    random_state=999)\n",
    "\n",
    "rfe = RFE(model, n_features_to_select=6)  # 선택할 특성의 개수를 지정합니다.\n",
    "\n",
    "all_columns = X.columns\n",
    "\n",
    "# RFE 알고리즘을 사용하여 특성 선택을 수행합니다.\n",
    "rfe_fit = rfe.fit(X, y)\n",
    "\n",
    "# 선택된 특성들을 출력합니다.\n",
    "selected_mask = rfe_fit.support_\n",
    "print(all_columns[selected_mask])\n",
    "print(rfe_fit.estimator_.feature_importances_)\n",
    "\n",
    "X = X_train[['Age', 'family', 'Fare', 'Sex_female', 'Embarked_S', 'Pclass_3']]\n",
    "test = X_test[['Age', 'family', 'Fare', 'Sex_female', 'Embarked_S', 'Pclass_3']]\n",
    "\n",
    "\n",
    "\n",
    "#SelectKBest을 활용한 특성 선택 탐색\n",
    "# from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# X = X_train.drop(columns=['Sex_male','Embarked_C','Pclass_1'])\n",
    "# y = y_train\n",
    "# test = X_test.drop(columns=['Sex_male','Embarked_C','Pclass_1'])\n",
    "\n",
    "# all_columns = X.columns\n",
    "\n",
    "# sel = SelectKBest(score_func=f_classif,k=6)\n",
    "# sel_fit = sel.fit(X,y)\n",
    "# X = sel_fit.transform(X)\n",
    "# test = sel_fit.transform(test)\n",
    "\n",
    "# selected_mask = sel_fit.get_support()\n",
    "# print(all_columns[selected_mask])\n",
    "# print(X)\n",
    "# print(test)\n",
    "\n",
    "# print(all_columns)\n",
    "# print(sel_fit.scores_.astype('int'))\n",
    "\n",
    "# X = X_train[['Age','family','Sex_female','Embarked_S','Pclass_2','Pclass_3']]\n",
    "# y = y_train\n",
    "# test = X_test[['Age','family','Sex_female','Embarked_S','Pclass_2','Pclass_3']]\n",
    "\n",
    "\n",
    "\n",
    "#statsmodels.Logit() 통계적 분석 결과 표(p-value, coef 값)를 통한 특성 선택 \n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# X = X_train.drop(columns=['Sex_male','Embarked_C','Pclass_1'])\n",
    "# y = y_train\n",
    "# test = X_test.drop(columns=['Sex_male','Embarked_C','Pclass_1'])\n",
    "\n",
    "# model = sm.Logit(y,X)\n",
    "# model_fit = model.fit()\n",
    "# print(model_fit.summary())\n",
    "\n",
    "# X = X_train[['Age','Fare','Sex_female','Embarked_S','Pclass_2','Pclass_3']]\n",
    "# y = y_train\n",
    "# test = X_test[['Age','Fare','Sex_female','Embarked_S','Pclass_2','Pclass_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f872b0-fde5-4e5f-821f-dee3d309e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression best parameter: OrderedDict([('C', 45.95039732036445), ('max_iter', 645)])\n",
      "RandomForestClassifier best parameter: OrderedDict([('max_depth', 16), ('min_samples_leaf', 4), ('min_samples_split', 9), ('n_estimators', 93)])\n",
      "XGBClassifier best parameter: OrderedDict([('learning_rate', 0.690570437583915), ('max_depth', 9), ('min_child_weight', 17), ('n_estimators', 356), ('subsample', 0.7242771491724633)])\n",
      "LGBMClassifier best parameter: OrderedDict([('learning_rate', 0.24148357781556884), ('max_depth', 12), ('min_child_weight', 16), ('n_estimators', 670), ('num_leaves', 630)])\n"
     ]
    }
   ],
   "source": [
    "#8.하이퍼파라미터 최적화\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "    'LGBMClassifier': LGBMClassifier(verbose=-1)\n",
    "    # 'CatBoostClassifier': CatBoostClassifier()\n",
    "}\n",
    "\n",
    "# 하이퍼파라미터 탐색 범위 지정\n",
    "search_space = {\n",
    "    'LogisticRegression': {\n",
    "        'max_iter': (100, 1000),\n",
    "        'C': (0.01, 100)\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': (10, 1000),   # 트리 개수\n",
    "        'max_depth': (3, 20),         # 트리 최대 깊이\n",
    "        'min_samples_split': (2, 10), # 분할을 위한 최소 샘플 수\n",
    "        'min_samples_leaf': (1, 10)   # 잎 노드에 필요한 최소 샘플 수\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'n_estimators': (10, 1000),\n",
    "        'max_depth': (3, 20),\n",
    "        'min_child_weight': (1, 20),\n",
    "        'learning_rate': (0.001, 1.0),\n",
    "        'subsample': (0.1,1)\n",
    "    },\n",
    "    'LGBMClassifier': {\n",
    "        'n_estimators': (10, 1000),\n",
    "        'max_depth': (3, 20),\n",
    "        'min_child_weight': (1, 20),\n",
    "        'learning_rate': (0.001, 1.0),\n",
    "        'num_leaves': (10,1000)\n",
    "    }\n",
    "    # 'CatBoostClassifier': {\n",
    "    #     'iterations': (10, 1000),\n",
    "    #     'depth': (3, 20),\n",
    "    #     'min_child_samples': (1, 20),\n",
    "    #     'learning_rate': (0.001, 1.0)\n",
    "    #     'l2_leaf_reg': (1,10)\n",
    "    # }\n",
    "}\n",
    "\n",
    "# 베이지안 최적화를 사용한 자동화된 하이퍼파라미터 튜닝\n",
    "best_params = {}\n",
    "for model_name, model in models.items():\n",
    "    opt = BayesSearchCV(\n",
    "        model,\n",
    "        search_space[model_name],\n",
    "        n_iter=10,   # 반복 횟수\n",
    "        cv=5,       # 교차 검증 폴드 수\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    opt.fit(X, y)\n",
    "    best_params[model_name] = opt.best_params_\n",
    "\n",
    "# 최적 하이퍼파라미터 출력\n",
    "for model_name, params in best_params.items():\n",
    "    print(model_name, \"best parameter:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f4a2184-da62-49b2-a10e-d876debd593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.모델 생성\n",
    "\n",
    "#LogisticRegression\n",
    "model_lr = LogisticRegression(\n",
    "                    max_iter=909,\n",
    "                    C=59.320,\n",
    "                    random_state=999)\n",
    "# model_lr.fit(X,y)\n",
    "# y_predict_lr = model_lr.predict(test)\n",
    "\n",
    "#RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(\n",
    "                    max_depth=7,\n",
    "                    n_estimators=200,\n",
    "                    max_features='sqrt',\n",
    "                    min_samples_split=2,\n",
    "                    min_samples_leaf=1,\n",
    "                    random_state=999)\n",
    "# model_rf.fit(X,y)\n",
    "# y_predict_rf = model_rf.predict(test)\n",
    "\n",
    "#XGBClassifier\n",
    "model_xgb = XGBClassifier(\n",
    "                    max_depth=5,\n",
    "                    n_estimators=461,\n",
    "                    min_child_weight=11,\n",
    "                    learning_rate=0.292,\n",
    "                    subsample=0.613,\n",
    "                    random_state=999)\n",
    "# model_xgb.fit(X,y)\n",
    "# y_predict_xgb = model_xgb.predict(test)\n",
    "\n",
    "#LGBMClassifier\n",
    "model_lgbm = LGBMClassifier(\n",
    "                    max_depth=11,\n",
    "                    n_estimators=52,\n",
    "                    min_child_weight=12,\n",
    "                    learning_rate=0.297,\n",
    "                    num_leaves=407,\n",
    "                    verbose=-1,\n",
    "                    random_state=999)\n",
    "# model_lgbm.fit(X,y)\n",
    "# y_predict_lgbm = model_lgbm.predict(test)\n",
    "\n",
    "#CatBoostClassifier\n",
    "# model_cat = CatBoostClassifier(\n",
    "#                     depth=2,\n",
    "#                     iterations=100,\n",
    "#                     learning_rate=0.2, \n",
    "#                     loss_function='MultiClass')\n",
    "# model_cat.fit(X,y,verbose=False)\n",
    "# y_predict_cat = model_cat.predict(test)\n",
    "# y_predict_cat = np.array(y_predict_cat).flatten() #array in array 형태를 array로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca3a8f3-e963-4f64-a9e4-328c46387ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808\n",
      "0.825\n",
      "0.818\n",
      "0.835\n"
     ]
    }
   ],
   "source": [
    "#10.모델 학습 및 평가\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "kfold = KFold(n_splits=5,shuffle=True,random_state=999)\n",
    "print(cross_validate(model_lr, X, y, cv=kfold, scoring='accuracy')['test_score'].mean().round(3))\n",
    "print(cross_validate(model_rf, X, y, cv=kfold, scoring='accuracy')['test_score'].mean().round(3))\n",
    "print(cross_validate(model_xgb, X, y, cv=kfold, scoring='accuracy')['test_score'].mean().round(3))\n",
    "print(cross_validate(model_lgbm, X, y, cv=kfold, scoring='accuracy')['test_score'].mean().round(3))\n",
    "# print(cross_validate(model_cat, X, y, cv=kfold, scoring='accuracy',fit_params={\"verbose\":False})['test_score'].mean().round(3))\n",
    "\n",
    "# 필요시 데이터 분리하기\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X1, X2, y1, y2 = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=999)\n",
    "\n",
    "# print(accuracy_score(y2,y_predict_lr).round(3))\n",
    "# print(f1_score(y2,y_predict_lr).round(3))\n",
    "# probas_lr = model_lr.predict_proba(X2)\n",
    "# print(roc_auc_score(y2,probas_lr[:,1]).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a67961c-afea-4ed0-a93c-94144df2e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.실 데이터 예측 및 제출\n",
    "model_rf = RandomForestClassifier(\n",
    "                    max_depth=7,\n",
    "                    n_estimators=200,\n",
    "                    max_features='sqrt',\n",
    "                    min_samples_split=2,\n",
    "                    min_samples_leaf=1,\n",
    "                    random_state=999)\n",
    "model_rf.fit(X,y)\n",
    "y_predict_rf = model_rf.predict(test)\n",
    "\n",
    "'''\n",
    "#Best Parameter\n",
    "model_rf = RandomForestClassifier(\n",
    "                    max_depth=7,\n",
    "                    n_estimators=200,\n",
    "                    max_features='sqrt',\n",
    "                    min_samples_split=2,\n",
    "                    min_samples_leaf=1,\n",
    "                    random_state=999)\n",
    "model_rf.fit(X,y)\n",
    "y_predict_rf = model_rf.predict(test)\n",
    "'''\n",
    "\n",
    "obj = {'PassengerId':PassengerId,'Survived':y_predict_rf}\n",
    "result = pd.DataFrame(obj)\n",
    "result.to_csv('result/result.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
